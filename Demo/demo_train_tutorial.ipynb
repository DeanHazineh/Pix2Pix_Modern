{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple walkthrough/tutorial on using Pix2Pix for the classic inverse problem of deep-learning color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To train code in a scalable fashion, use the trainer like in train.py. This lets you easily test many different configurations for your problem by changing the config.yaml file. The name of the pix2pix game is hyperparameter tuning to avoid mode collapse. The generator and the discriminator need to be evenly matched. Have fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Pix2pix code\n",
    "from pix2pix.data_demo.coco import COCO, reverse_transform\n",
    "from pix2pix import initialize_model\n",
    "\n",
    "# Visualize networks\n",
    "from torchview import draw_graph\n",
    "import graphviz\n",
    "graphviz.set_jupyter_format('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the example COCO dataloader included that has a few samples\n",
    "dataset = COCO(\n",
    "    root_dir=\"/home/deanhazineh/Downloads/Pix2Pix/pix2pix/data_demo/coco_2017_train_samples/\",\n",
    "    train_fold=\"COCO_2017_Train_Samples\",\n",
    "    num_dat=-1\n",
    ")\n",
    "train_test_split=0.9\n",
    "\n",
    "total_count = len(dataset)\n",
    "train_count = int(train_test_split * total_count)\n",
    "test_count = total_count - train_count\n",
    "train_dataset, test_dataset = random_split(dataset, [train_count, test_count])\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dl = DataLoader(test_dataset, batch_size=8, shuffle=False) \n",
    "\n",
    "xkey = \"L\"\n",
    "ykey = \"AB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_dl))\n",
    "L, AB = sample[xkey], sample[ykey]\n",
    "\n",
    "print(L.shape, L.min(), L.max())\n",
    "print(AB.shape, AB.min(), AB.max())\n",
    "\n",
    "disp_num = 6\n",
    "fig, ax = plt.subplots(2, disp_num, figsize=(3*disp_num, 6))\n",
    "for i in range(disp_num):\n",
    "    gs, rgb = reverse_transform(L[i], AB[i])\n",
    "    ax[0, i].imshow(gs, cmap='gray')\n",
    "    ax[1, i].imshow(rgb)\n",
    "\n",
    "for axi in ax.flatten():\n",
    "    axi.axis('off')\n",
    "ax[0,0].set_ylabel(\"Grayscale\")\n",
    "ax[1,0].set_ylabel(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = model.generator\n",
    "model_graph = draw_graph(generator,input_data=torch.rand((1, 1, 256, 256)))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = model.discriminator\n",
    "cond = torch.rand(1,1,256,256)\n",
    "targ = torch.rand(1,2,256,256)\n",
    "model_graph = draw_graph(discriminator, input_data=(cond, targ))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We code out the training loop in full for a tutorial but you can skip this and use the trainer as shown in the demo_train code\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import itertools  # NEVER USE ITERTOOLS.CYCLE ON TRAINING DATA WITH RANDOM AUGMENTATIONS\n",
    "from matplotlib import gridspec\n",
    "\n",
    "def compute_ema(data, alpha=0.1):\n",
    "    ema = [data[0]]  \n",
    "    for i in range(1, len(data)):\n",
    "        ema.append(alpha * data[i] + (1 - alpha) * ema[i - 1])\n",
    "    return np.array(ema)\n",
    "\n",
    "def plot_losses(losses):\n",
    "    lw = 1\n",
    "    alp = 0.2\n",
    "\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "\n",
    "    ax[0].plot(losses[\"l1_loss\"], 'bo', alpha=alp)\n",
    "    ax[0].plot(compute_ema(losses[\"l1_loss\"]), 'b-', linewidth=lw, label=\"L1 Loss\")\n",
    "    ax[0].set_title(\"Generator L1 Loss\")\n",
    "    ax[0].grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    ax[1].plot(losses[\"loss_D\"], 'ko', alpha=alp)\n",
    "    ax[1].plot(compute_ema(losses[\"loss_D\"]), 'k-', linewidth=lw, label=\"Discriminator Loss\")\n",
    "    ax[1].plot(losses[\"gan_loss\"], 'ro', alpha=alp)\n",
    "    ax[1].plot(compute_ema(losses[\"gan_loss\"]), 'r-', linewidth=lw, label=\"Generator-GAN Loss\")\n",
    "    ax[1].plot([0, len(losses[\"loss_D\"])], [0.69, 0.69], 'k--')\n",
    "    ax[1].legend()\n",
    "\n",
    "    fig.tight_layout()  \n",
    "    plt.savefig(\"./out_tutorial/losses.png\")\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def visualize(real_A, real_B, disp_num, reverse_transform, save_to=None):\n",
    "    pred_B = model.forward(real_A)\n",
    "    snum = np.minimum(disp_num, pred_B.shape[0])\n",
    "    fig, ax = plt.subplots(3, snum, figsize=(3 * snum, 9))\n",
    "    for i in range(snum):\n",
    "        gs, rgb = reverse_transform(real_A[i], pred_B[i])\n",
    "        _, rgb_gt = reverse_transform(real_A[i], real_B[i])\n",
    "        ax[0, i].imshow(gs, cmap=\"gray\")\n",
    "        ax[1, i].imshow(rgb)\n",
    "        ax[2, i].imshow(rgb_gt)\n",
    "\n",
    "    for axi in ax.flatten():\n",
    "        axi.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_to is not None:\n",
    "        plt.savefig(save_to)\n",
    "        plt.close()\n",
    "\n",
    "    return\n",
    "\n",
    "###\n",
    "\n",
    "if not os.path.exists(\"./out_tutorial/\"):\n",
    "    os.makedirs(\"./out_tutorial/\")\n",
    "\n",
    "valid_iter = itertools.cycle(test_dl) # used for visualization\n",
    "train_iter = itertools.cycle(train_dl) # used for visualization (Never train with itertools)\n",
    "\n",
    "optimizer_G = optim.Adam(model.generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(model.discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "if os.path.exists(\"./out_tutorial/ckpt_last.ckpt\"):\n",
    "    ckpt_dict = torch.load(\"./out_tutorial/ckpt_last.ckpt\", map_location=\"cpu\")\n",
    "    model.load_state_dict(ckpt_dict[\"state_dict\"])\n",
    "    model.to('cuda')\n",
    "\n",
    "    optimizer_G.load_state_dict(ckpt_dict[\"optimizer_G_state_dict\"])\n",
    "    optimizer_D.load_state_dict(ckpt_dict[\"optimizer_D_state_dict\"])\n",
    "\n",
    "    epoch = ckpt_dict[\"epoch\"]\n",
    "    losses = ckpt_dict[\"losses\"]\n",
    "    print(f\"Loaded checkpoint from epoch {epoch}\")\n",
    "else:\n",
    "    model.to(\"cuda\")\n",
    "    epoch = 0\n",
    "    losses = {\n",
    "        \"loss_D\": [],\n",
    "        \"loss_D_real\": [],\n",
    "        \"loss_D_fake\": [],\n",
    "        \"loss_G\": [],\n",
    "        \"gan_loss\": [],\n",
    "        \"l1_loss\": []\n",
    "    }\n",
    "\n",
    "disp_num = 6\n",
    "max_epochs = 100\n",
    "snapshot_every_n=10\n",
    "for ep in np.arange(epoch, max_epochs):\n",
    "    \n",
    "    ### Training step\n",
    "    epoch_loss_D = 0\n",
    "    epoch_loss_D_real = 0\n",
    "    epoch_loss_D_fake = 0\n",
    "    epoch_loss_G = 0\n",
    "    epoch_gan_loss = 0\n",
    "    epoch_l1_loss = 0\n",
    "    ldl = len(train_dl)\n",
    "    for sample in train_dl:\n",
    "        real_A = sample[xkey].to(dtype=torch.float32, device='cuda')\n",
    "        real_B = sample[ykey].to(dtype=torch.float32, device='cuda')\n",
    "        fake_B = model.generator(real_A)\n",
    "\n",
    "        model.discriminator.train()\n",
    "        optimizer_D.zero_grad()\n",
    "        loss_D, loss_D_real, loss_D_fake = model.compute_discriminator_loss(\n",
    "            real_A, real_B, fake_B\n",
    "        )\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        epoch_loss_D += loss_D.item()/ldl\n",
    "        epoch_loss_D_real += loss_D_real.item()/ldl\n",
    "        epoch_loss_D_fake += loss_D_fake.item()/ldl\n",
    "\n",
    "        model.generator.train()\n",
    "        optimizer_G.zero_grad()\n",
    "        loss_G, gan_loss, l1_loss = model.compute_generator_loss(\n",
    "            real_A, real_B\n",
    "        )\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        epoch_loss_G += loss_G.item()/ldl\n",
    "        epoch_gan_loss += gan_loss.item()/ldl\n",
    "        epoch_l1_loss += l1_loss.item()/ldl\n",
    "\n",
    "    losses[\"loss_D\"].append( epoch_loss_D)\n",
    "    losses[\"loss_D_real\"].append( epoch_loss_D_real)\n",
    "    losses[\"loss_D_fake\"].append( epoch_loss_D_fake)\n",
    "    losses[\"loss_G\"].append(epoch_loss_G)\n",
    "    losses[\"gan_loss\"].append(epoch_gan_loss)\n",
    "    losses[\"l1_loss\"].append(epoch_l1_loss)\n",
    "    print(f\"epoch: {ep} Gen. Loss: {epoch_loss_G:.3f} Disc. Loss: {epoch_loss_D:.3f}\")\n",
    "\n",
    "    if ep % snapshot_every_n == 0:\n",
    "        plot_losses(losses)\n",
    "\n",
    "        model.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            sample = next(train_iter)\n",
    "            real_A = sample[xkey].to(dtype=torch.float32, device='cuda')\n",
    "            real_B = sample[ykey].to(dtype=torch.float32, device='cuda')\n",
    "            visualize(real_A, real_B, disp_num=disp_num, reverse_transform=reverse_transform, save_to=f\"./out_tutorial/train_{ep+1}.png\")\n",
    "            \n",
    "            sample = next(valid_iter)\n",
    "            real_A = sample[xkey].to(dtype=torch.float32, device='cuda')\n",
    "            real_B = sample[ykey].to(dtype=torch.float32, device='cuda')\n",
    "            visualize(real_A, real_B, disp_num=disp_num, reverse_transform=reverse_transform, save_to=f\"./out_tutorial/test_{ep+1}.png\")\n",
    "\n",
    "        state = {\n",
    "            \"epoch\": ep+1,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer_D_state_dict\": optimizer_D.state_dict(),\n",
    "            \"optimizer_G_state_dict\": optimizer_G.state_dict(),\n",
    "            \"losses\": losses\n",
    "        }\n",
    "        torch.save(state, \"./out_tutorial/ckpt_last.ckpt\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt_spec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
